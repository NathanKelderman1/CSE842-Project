{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2e8a019c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.ticker as ticker\n",
    "import warnings\n",
    "import scipy.stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, LSTM, Embedding, Dropout\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from nltk.corpus import stopwords\n",
    "from time import sleep\n",
    "import sys\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from scipy import sparse as sp_sparse\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score \n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00d30d5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Anonymized Message</th>\n",
       "      <th>Valence</th>\n",
       "      <th>Arousal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Strolling down memory lane in the name of new ...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hey yall. I'm going to tennis camp tommorow.</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>... chocolate peanutbutter ice cream, yes plea...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NOTHING leave me alone!!!!!!!!!!!!!!!!!</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Anonymized Message  Valence  Arousal\n",
       "0  Strolling down memory lane in the name of new ...      6.0      4.0\n",
       "1       Hey yall. I'm going to tennis camp tommorow.      5.0      3.0\n",
       "2                                                         6.0      2.0\n",
       "3  ... chocolate peanutbutter ice cream, yes plea...      6.0      5.0\n",
       "4            NOTHING leave me alone!!!!!!!!!!!!!!!!!      4.0      9.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers = ['Anonymized Message', 'Valence', 'Arousal']\n",
    "dtypes = {'Anonymized Message':'str', 'Valence':'float', 'Arousal':'float'}\n",
    "data = pd.read_csv(\"dataset-fb-valence-arousal-anon.csv\", encoding='utf8', skiprows=[0], names=headers, dtype=dtypes, na_filter=False)\n",
    "data = data.sample(frac=1).reset_index(drop=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a1c900eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set all words to lowercase and remove anything that isn't a letter or space\n",
    "data['Anonymized Message'] = data['Anonymized Message'].apply(lambda x: x.lower()) #transform text to lowercase\n",
    "data['Anonymized Message'] = data['Anonymized Message'].apply(lambda x: re.sub('[^a-zA-z0-9\\s]', '', x))\n",
    "data['Anonymized Message'] = data['Anonymized Message'].apply(lambda x: re.sub('[_\\\\/(){}\\[\\]\\|@,;]', '', x))\n",
    "\n",
    "# find and remove all stop words\n",
    "stop = stopwords.words('english')\n",
    "data['Anonymized Message'] = data['Anonymized Message'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0f2e969d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2389    3rd overall 50k fanball fantasy football sure ...\n",
       "1480                   7 months im jobless homeless happy\n",
       "5752                                                     \n",
       "4758    wow havent thank everyone happy bday congrates...\n",
       "2357    may 18th better day get move new house sex cra...\n",
       "3974                                                bored\n",
       "Name: Anonymized Message, dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    # split X, y into training and testing \n",
    "    X, X_test, y, y_test = train_test_split(data['Anonymized Message'], data['Valence'], test_size=0.2, random_state=0)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X,y,test_size = 0.25)\n",
    "    X_train[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e92ae8ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['im', 'person', 'day', 'like', 'love', 'today', 'time', 'go', 'one', 'get']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dictionary of all words from train corpus with their counts.\n",
    "words_counts = {}\n",
    "for comments in X_train:\n",
    "    for word in comments.split():\n",
    "        if word not in words_counts:\n",
    "            words_counts[word] = 1\n",
    "        words_counts[word] += 1\n",
    "        \n",
    "DICT_SIZE = 10000\n",
    "POPULAR_WORDS = sorted(words_counts, key=words_counts.get, reverse=True)[:DICT_SIZE]\n",
    "WORDS_TO_INDEX = {key: rank for rank, key in enumerate(POPULAR_WORDS, 0)}\n",
    "INDEX_TO_WORDS = {index:word for word, index in WORDS_TO_INDEX.items()}\n",
    "ALL_WORDS = WORDS_TO_INDEX.keys()\n",
    "POPULAR_WORDS[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1e25e2dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape  (3474, 10000) \n",
      "X_val shape  (1158, 10000)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def my_bag_of_words(text, words_to_index, dict_size):\n",
    "    \"\"\"\n",
    "        text: a string\n",
    "        dict_size: size of the dictionary\n",
    "        \n",
    "        return a vector which is a bag-of-words representation of 'text'\n",
    "    \"\"\"\n",
    "    result_vector = np.zeros(dict_size)\n",
    "    for word in text.split(' '):\n",
    "        if word in words_to_index:\n",
    "            result_vector[words_to_index[word]] +=1\n",
    "    return result_vector\n",
    "\n",
    "X_train_mybag = sp_sparse.vstack([sp_sparse.csr_matrix(my_bag_of_words(text, WORDS_TO_INDEX, DICT_SIZE)) for text in X_train])\n",
    "X_val_mybag = sp_sparse.vstack([sp_sparse.csr_matrix(my_bag_of_words(text, WORDS_TO_INDEX, DICT_SIZE)) for text in X_val])\n",
    "print('X_train shape ', X_train_mybag.shape, '\\nX_val shape ', X_val_mybag.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e4480ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def tfidf_features(X_train, X_val, X_test):\n",
    "    \"\"\"\n",
    "        X_train, X_test — samples        \n",
    "        return TF-IDF vectorized representation of each sample and vocabulary\n",
    "    \"\"\"\n",
    "    # Create TF-IDF vectorizer with a proper parameters choice\n",
    "    # Fit the vectorizer on the train set\n",
    "    # Transform the train, test set and return the result\n",
    "    \n",
    "    \n",
    "    tfidf_vectorizer = TfidfVectorizer(ngram_range=(1,2), max_df=0.9, min_df=5, token_pattern='(\\S+)')\n",
    "\n",
    "    X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "    X_val_tfidf = tfidf_vectorizer.transform(X_val)\n",
    "    X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "    \n",
    "    return X_train_tfidf, X_val_tfidf, X_test_tfidf, tfidf_vectorizer.vocabulary_\n",
    "\n",
    "X_train_tfidf, X_val_tfidf, X_test_tfidf, tfidf_vocab = tfidf_features(X_train, X_val, X_test)\n",
    "tfidf_reversed_vocab = {i:word for word,i in tfidf_vocab.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "76c18728",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier(X_train, y_train, C, regularisation):\n",
    "    \"\"\"\n",
    "      X_train, y_train — training data\n",
    "      \n",
    "      return: trained classifier\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create and fit LogisticRegression wraped into OneVsRestClassifier.\n",
    "\n",
    "    model = OneVsRestClassifier(LogisticRegression(penalty=regularisation, C=C, max_iter=10000)).fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "classifier_mybag = train_classifier(X_train_mybag, y_train, C = 4, regularisation = 'l2')\n",
    "classifier_tfidf = train_classifier(X_train_tfidf, y_train, C = 4, regularisation = 'l2')\n",
    "\n",
    "y_val_predicted_labels_mybag = classifier_mybag.predict(X_val_mybag)\n",
    "y_val_predicted_labels_tfidf = classifier_tfidf.predict(X_val_tfidf)\n",
    "y_val_predicted_scores_mybag = classifier_mybag.decision_function(X_val_mybag)\n",
    "y_val_predicted_scores_tfidf = classifier_tfidf.decision_function(X_val_tfidf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
