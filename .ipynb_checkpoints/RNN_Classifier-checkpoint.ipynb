{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "dc3335fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from collections import defaultdict\n",
    "import os, sys, numpy as np\n",
    "\n",
    "data = open(\"dataset-fb-valence-arousal-anon.csv\", encoding=\"utf8\")\n",
    "#Read and skip first line\n",
    "data.readline()\n",
    "corpora = []\n",
    "scores = [] #this is the score for corpora at the same index, first value in pair is valence, second arousal\n",
    "\n",
    "#Parse data\n",
    "for line in data.readlines():\n",
    "    msg, quantifiers = parse_data(line)\n",
    "    v1 = quantifiers[0]\n",
    "    v2 = quantifiers[1]\n",
    "    a1 = quantifiers[2]\n",
    "    a2 = quantifiers[3]\n",
    "    update_data(msg, v1, v1_data)\n",
    "    update_data(msg, v2, v2_data)\n",
    "    update_data(msg, a1, a1_data)\n",
    "    update_data(msg, a2, a2_data)\n",
    "    corpora.append(msg)\n",
    "    vAvg = (int(v1)+int(v2))//2\n",
    "    aAvg = (int(a1)+int(a2))//2\n",
    "    scores.append((vAvg, aAvg))\n",
    "    \n",
    "for value in v1_data.keys():\n",
    "    data_list = v1_data[value]\n",
    "    \n",
    "    #split data list in half for training and testing\n",
    "    length = len(data_list)\n",
    "    \n",
    "    train_list = data_list[:length//2]\n",
    "    create_data_file(\"Train/v1_training.csv\", train_list, int(value))\n",
    "    \n",
    "    test_list = data_list[length//2:]\n",
    "    create_data_file(\"Test/v1_testing.csv\", test_list, int(value))\n",
    "    \n",
    "    \n",
    "for value in v2_data.keys():\n",
    "    data_list = v2_data[value]\n",
    "    \n",
    "    #split data list in half for training and testing\n",
    "    length = len(data_list)\n",
    "    \n",
    "    train_list = data_list[:length//2]\n",
    "    create_data_file(\"Train/v2_training.csv\", train_list, int(value))\n",
    "    \n",
    "    test_list = data_list[length//2:]\n",
    "    create_data_file(\"Test/v2_testing.csv\", test_list, int(value))\n",
    "    \n",
    "for value in a1_data.keys():\n",
    "    data_list = a1_data[value]\n",
    "    \n",
    "    #split data list in half for training and testing\n",
    "    length = len(data_list)\n",
    "    \n",
    "    train_list = data_list[:length//2]\n",
    "    create_data_file(\"Train/a1_training.csv\", train_list, int(value))\n",
    "    \n",
    "    test_list = data_list[length//2:]\n",
    "    create_data_file(\"Test/a1_testing.csv\", test_list, int(value))\n",
    "    \n",
    "for value in a2_data.keys():\n",
    "    data_list = a2_data[value]\n",
    "  \n",
    "    #split data list in half for training and testing\n",
    "    length = len(data_list)\n",
    "    \n",
    "    train_list = data_list[:length//2]\n",
    "    create_data_file(\"Train/a2_training.csv\", train_list, int(value))\n",
    "    \n",
    "    test_list = data_list[length//2:]\n",
    "    create_data_file(\"Test/a2_testing.csv\", test_list, int(value))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "b02342ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "vectorizer = CountVectorizer(corpora)\n",
    "vocab = vectorizer.fit_transform(corpora)\n",
    "\n",
    "#initialize some values\n",
    "#tensors = vocab.toarray()\n",
    "\n",
    "def process_file():\n",
    "    input = []\n",
    "    word_regx = re.compile('^[a-z]*$')\n",
    "    for sentence in corpora:\n",
    "        words = sentence.split(\" \")\n",
    "        for word in words:\n",
    "            word = re.sub('[.,!?\\\\-()\\\"]', \"\", word).lower()\n",
    "            match = word_regx.match(word)\n",
    "            if match != None and word not in input:\n",
    "                input.append(word)\n",
    "    return input\n",
    "\n",
    "def tensorize_sentence(sentence):\n",
    "    sentence = re.sub('[.,!?\\\\-()\\\"]', \"\", sentence).lower()\n",
    "    words = sentence.split(\" \")\n",
    "    sentence_tokens = [word for word in words if word in tokens]\n",
    "    tensor = torch.zeros(len(sentence_tokens), 1, len(tokens))\n",
    "    for index, word in enumerate(sentence_tokens):\n",
    "        i = tokens.index(word)\n",
    "        tensor[index][0][i] = 1\n",
    "    return tensor\n",
    "\n",
    "tokens = process_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "b2e386bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import random\n",
    "import string\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.i2o = nn.Linear(input_size + hidden_size, output_size)\n",
    "        self.activate = nn.Tanh()\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        combined = torch.cat((input, hidden), 1)\n",
    "        hidden = self.i2h(combined)\n",
    "        output = self.i2o(combined)\n",
    "        output = self.activate(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, self.hidden_size)\n",
    "\n",
    "# set values used for training iterations\n",
    "criterion = nn.NLLLoss()\n",
    "learning_rate = 0.000001\n",
    "iterations = 10000\n",
    "print_freq = 100\n",
    "\n",
    "# Define words used to identify names\n",
    "dictionary = {}\n",
    "n_words = len(dictionary)\n",
    "\n",
    "# Define categories for naming\n",
    "s1 = \"1\"\n",
    "s2 = \"2\"\n",
    "s3 = \"3\"\n",
    "s4 = \"4\"\n",
    "s5 = \"5\"\n",
    "s6 = \"6\"\n",
    "s7 = \"7\"\n",
    "s8 = \"8\"\n",
    "s9 = \"9\"\n",
    "categories = [s1, s2, s3, s4, s5, s6, s7, s8, s9]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "788cac5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin training model using training data.\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✓\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✓\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✓\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✓\n",
      "✗\n",
      "✓\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n"
     ]
    }
   ],
   "source": [
    "def train(category_tensor, sentence_tensor):\n",
    "    hidden = rnn.initHidden()\n",
    "\n",
    "    rnn.zero_grad()\n",
    "    for i in range(sentence_tensor.size()[0]):\n",
    "        word_tensor = sentence_tensor[i].clone().detach()#torch.tensor(sentence_tensor[i], dtype=torch.long)\n",
    "        output, hidden = rnn(word_tensor, hidden)\n",
    "\n",
    "    loss = criterion(output, category_tensor)\n",
    "    loss.backward()\n",
    "\n",
    "    # Add parameters' gradients to their values, multiplied by learning rate\n",
    "    for p in rnn.parameters():\n",
    "        p.data.add_(p.grad.data, alpha=-learning_rate)\n",
    "\n",
    "    return output, loss.item()\n",
    "\n",
    "\n",
    "def getCategoryFromOutput (output):\n",
    "    top_n, top_i = output.topk(1)\n",
    "    category_index = top_i[0].item()\n",
    "    return categories[category_index], category_index\n",
    "\n",
    "\n",
    "#Train RNN to clasify valence first\n",
    "n_hidden = 1\n",
    "n_categories = len(categories)\n",
    "n_words = len(tokens)\n",
    "rnn = RNN(n_words, n_hidden, n_categories)\n",
    "\n",
    "# Establish loss tracking variables\n",
    "current_loss = 0\n",
    "all_losses = []\n",
    "\n",
    "# Start trainin\n",
    "print(\"Begin training model to guess valence scores using training data.\")\n",
    "for i in range(iterations):\n",
    "    val = random.randint(0, 2316)\n",
    "    sentence_tensor = tensorize_sentence(corpora[val])\n",
    "    if sentence_tensor.numel() == 0:\n",
    "        continue\n",
    "    category_tensor = torch.tensor([scores[val][0] - 1], dtype=torch.long)\n",
    "    category = categories[category_tensor[0]]\n",
    "    output, loss = train(category_tensor, sentence_tensor)\n",
    "    current_loss += loss\n",
    "    guess, guess_i = getCategoryFromOutput(output)\n",
    "    if i % print_freq == 0:\n",
    "        correct = '✓' if guess == category else '✗'\n",
    "        print(correct)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "6eb2f20b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valence training has completed. Parsing testing data.\n",
      "Creating confusion matrix.\n",
      "Normalizing data.\n",
      "\n",
      "Results:\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.2000, 0.0000, 0.0000, 0.7000, 0.1000],\n",
      "        [0.0000, 0.2105, 0.1053, 0.0000, 0.2105, 0.0000, 0.0000, 0.3947, 0.0789],\n",
      "        [0.0000, 0.2151, 0.0968, 0.0000, 0.2151, 0.0000, 0.0000, 0.4194, 0.0538],\n",
      "        [0.0000, 0.1917, 0.0414, 0.0000, 0.3083, 0.0038, 0.0000, 0.3910, 0.0639],\n",
      "        [0.0000, 0.2453, 0.0189, 0.0000, 0.2264, 0.0000, 0.0000, 0.4811, 0.0283],\n",
      "        [0.0000, 0.2400, 0.0400, 0.0000, 0.2800, 0.0000, 0.0000, 0.3800, 0.0600],\n",
      "        [0.0000, 0.3750, 0.1250, 0.0000, 0.3750, 0.0000, 0.0000, 0.1250, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000]])\n",
      "The model was able to correctly evaluate arousal with an accuracy of  15%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Valence training has completed. Parsing testing data.\")\n",
    "# After training has completed, establish a confusion matrix to determine accuracy\n",
    "# Keep track of correct guesses in a confusion matrix\n",
    "confusion = torch.zeros(n_categories, n_categories)\n",
    "\n",
    "# Return an evaluation based on the current training data\n",
    "def classifySentence(sentence_tensor):\n",
    "    hidden = rnn.initHidden()\n",
    "\n",
    "    for i in range(sentence_tensor.size()[0]):\n",
    "        word_tensor = sentence_tensor[i].clone().detach()\n",
    "        output, hidden = rnn(word_tensor, hidden)\n",
    "    return getCategoryFromOutput(output)\n",
    "\n",
    "# Try values at random and record results\n",
    "print(\"Creating confusion matrix.\")\n",
    "correct = 0\n",
    "total = 0\n",
    "for i in range(2317, 2895):\n",
    "    sentence_tensor = tensorize_sentence(corpora[i])\n",
    "    category_tensor = torch.tensor([scores[i][0] - 1], dtype=torch.long)\n",
    "    category = categories[category_tensor[0]]\n",
    "    \n",
    "    if sentence_tensor.numel() == 0:\n",
    "        continue\n",
    "    \n",
    "    guess, guess_i = classifySentence(sentence_tensor)\n",
    "    category_i = categories.index(category)\n",
    "    if category_i == guess_i:\n",
    "        correct += 1\n",
    "    total += 1\n",
    "    confusion[category_i][guess_i] += 1\n",
    "\n",
    "# Normalize by dividing every row by its sum\n",
    "print(\"Normalizing data.\")\n",
    "for i in range(n_categories):\n",
    "    confusion[i] = confusion[i] / confusion[i].sum()\n",
    "\n",
    "print(\"\\nResults:\")\n",
    "print('The model was able to correctly evaluate valence with an accuracy of %3d%%\\n' % (correct/total * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "941e7483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin training model to guess arousal scores using training data.\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✓\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✓\n",
      "✗\n",
      "✓\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✓\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✓\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✓\n",
      "✗\n",
      "✗\n",
      "✓\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✓\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n",
      "✗\n"
     ]
    }
   ],
   "source": [
    "# Start trainin\n",
    "rnn = RNN(n_words, n_hidden, n_categories)\n",
    "\n",
    "print(\"Begin training model to guess arousal scores using training data.\")\n",
    "for i in range(iterations):\n",
    "    val = random.randint(0, 2316)\n",
    "    sentence_tensor = tensorize_sentence(corpora[val])\n",
    "    if sentence_tensor.numel() == 0:\n",
    "        continue\n",
    "    category_tensor = torch.tensor([scores[val][1] - 1], dtype=torch.long)\n",
    "    category = categories[category_tensor[0]]\n",
    "    output, loss = train(category_tensor, sentence_tensor)\n",
    "    current_loss += loss\n",
    "    guess, guess_i = getCategoryFromOutput(output)\n",
    "    if i % print_freq == 0:\n",
    "        correct = '✓' if guess == category else '✗'\n",
    "        print(correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "716686ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valence training has completed. Parsing testing data.\n",
      "Creating confusion matrix.\n",
      "Normalizing data.\n",
      "\n",
      "Results:\n",
      "The model was able to correctly evaluate arousal with an accuracy of  15%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Valence training has completed. Parsing testing data.\")\n",
    "# After training has completed, establish a confusion matrix to determine accuracy\n",
    "# Keep track of correct guesses in a confusion matrix\n",
    "confusion = torch.zeros(n_categories, n_categories)\n",
    "\n",
    "# Return an evaluation based on the current training data\n",
    "def classifySentence(sentence_tensor):\n",
    "    hidden = rnn.initHidden()\n",
    "\n",
    "    for i in range(sentence_tensor.size()[0]):\n",
    "        word_tensor = sentence_tensor[i].clone().detach()\n",
    "        output, hidden = rnn(word_tensor, hidden)\n",
    "    return getCategoryFromOutput(output)\n",
    "\n",
    "# Try values at random and record results\n",
    "print(\"Creating confusion matrix.\")\n",
    "correct = 0\n",
    "total = 0\n",
    "for i in range(2317, 2895):\n",
    "    sentence_tensor = tensorize_sentence(corpora[i])\n",
    "    category_tensor = torch.tensor([scores[i][0] - 1], dtype=torch.long)\n",
    "    category = categories[category_tensor[0]]\n",
    "    \n",
    "    if sentence_tensor.numel() == 0:\n",
    "        continue\n",
    "    \n",
    "    guess, guess_i = classifySentence(sentence_tensor)\n",
    "    category_i = categories.index(category)\n",
    "    \n",
    "    if category_i == guess_i:\n",
    "        correct += 1\n",
    "    total += 1\n",
    "    confusion[category_i][guess_i] += 1\n",
    "\n",
    "# Normalize by dividing every row by its sum\n",
    "print(\"Normalizing data.\")\n",
    "for i in range(n_categories):\n",
    "    confusion[i] = confusion[i] / confusion[i].sum()\n",
    "\n",
    "print(\"\\nResults:\")\n",
    "print('The model was able to correctly evaluate arousal with an accuracy of %3d%%\\n' % (correct/total * 100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
