{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7c3ee45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from collections import defaultdict\n",
    "import os, sys, numpy as np\n",
    "\n",
    "#Parse data into testing and training examples\n",
    "def parse_data(line):\n",
    "    data = []\n",
    "    \n",
    "    #If line starts with a quotation mark, then there is a comma in the data and rsplit must be used\n",
    "    if line.startswith(\"\\\"\"):\n",
    "        #find the ending quotation mark to create msg substring\n",
    "        data = line.rsplit(\",\", 4)\n",
    "    else:\n",
    "        data = line.split(\",\")\n",
    "    \n",
    "    msg = data.pop(0)\n",
    "    quantifiers = data\n",
    "    return msg, quantifiers\n",
    "    \n",
    "\n",
    "def update_data(msg, value, data):\n",
    "    if msg not in data[value]:\n",
    "        data[value].append(msg)\n",
    "    \n",
    "    \n",
    "\n",
    "def create_data_file(filename, data, value):\n",
    "    output = open(filename, \"a\", encoding=\"utf8\")\n",
    "    for item in data:\n",
    "        output.write(\"%s, %d\\n\" % (item, value))\n",
    "    output.close()\n",
    "    \n",
    "    \n",
    "a1_data = defaultdict(list)\n",
    "a2_data = defaultdict(list)\n",
    "v1_data = defaultdict(list)\n",
    "v2_data = defaultdict(list)\n",
    "\n",
    "data = open(\"dataset-fb-valence-arousal-anon.csv\", encoding=\"utf8\")\n",
    "#Read and skip first line\n",
    "data.readline()\n",
    "corpora = []\n",
    "scores = [] #this is the score for corpora at the same index, first value in pair is valence, second arousal\n",
    "\n",
    "#Parse data\n",
    "for line in data.readlines():\n",
    "    msg, quantifiers = parse_data(line)\n",
    "    v1 = quantifiers[0]\n",
    "    v2 = quantifiers[1]\n",
    "    a1 = quantifiers[2]\n",
    "    a2 = quantifiers[3]\n",
    "    update_data(msg, v1, v1_data)\n",
    "    update_data(msg, v2, v2_data)\n",
    "    update_data(msg, a1, a1_data)\n",
    "    update_data(msg, a2, a2_data)\n",
    "    corpora.append(msg)\n",
    "    vAvg = (int(v1)+int(v2))//2\n",
    "    aAvg = (int(a1)+int(a2))//2\n",
    "    scores.append((vAvg, aAvg))\n",
    "    \n",
    "for value in v1_data.keys():\n",
    "    data_list = v1_data[value]\n",
    "    \n",
    "    #split data list in half for training and testing\n",
    "    length = len(data_list)\n",
    "    \n",
    "    train_list = data_list[:length//2]\n",
    "    create_data_file(\"Train/v1_training.csv\", train_list, int(value))\n",
    "    \n",
    "    test_list = data_list[length//2:]\n",
    "    create_data_file(\"Test/v1_testing.csv\", test_list, int(value))\n",
    "    \n",
    "    \n",
    "for value in v2_data.keys():\n",
    "    data_list = v2_data[value]\n",
    "    \n",
    "    #split data list in half for training and testing\n",
    "    length = len(data_list)\n",
    "    \n",
    "    train_list = data_list[:length//2]\n",
    "    create_data_file(\"Train/v2_training.csv\", train_list, int(value))\n",
    "    \n",
    "    test_list = data_list[length//2:]\n",
    "    create_data_file(\"Test/v2_testing.csv\", test_list, int(value))\n",
    "    \n",
    "for value in a1_data.keys():\n",
    "    data_list = a1_data[value]\n",
    "    \n",
    "    #split data list in half for training and testing\n",
    "    length = len(data_list)\n",
    "    \n",
    "    train_list = data_list[:length//2]\n",
    "    create_data_file(\"Train/a1_training.csv\", train_list, int(value))\n",
    "    \n",
    "    test_list = data_list[length//2:]\n",
    "    create_data_file(\"Test/a1_testing.csv\", test_list, int(value))\n",
    "    \n",
    "for value in a2_data.keys():\n",
    "    data_list = a2_data[value]\n",
    "  \n",
    "    #split data list in half for training and testing\n",
    "    length = len(data_list)\n",
    "    \n",
    "    train_list = data_list[:length//2]\n",
    "    create_data_file(\"Train/a2_training.csv\", train_list, int(value))\n",
    "    \n",
    "    test_list = data_list[length//2:]\n",
    "    create_data_file(\"Test/a2_testing.csv\", test_list, int(value))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8374d05d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[0 0 0 ... 0 0 0]\n",
      "5.888442711112049\n",
      "[0 0 0 ... 0 0 0]\n",
      "2.754033784338631\n",
      "[0 0 0 ... 0 0 0]\n",
      "1.688728268896487\n",
      "[0 0 0 ... 0 0 0]\n",
      "8.712522851123037\n",
      "[0 0 0 ... 0 0 0]\n",
      "2.2483798418446033\n",
      "[0 0 0 ... 0 0 0]\n",
      "2.5805543605424694\n",
      "[0 0 0 ... 0 0 0]\n",
      "4.618608323884309\n",
      "[0 0 0 ... 0 0 0]\n",
      "16.81623559067609\n",
      "[0 0 0 ... 0 0 0]\n",
      "7.203351178864781\n",
      "[0 0 0 ... 0 0 0]\n",
      "2.853933134295421\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(corpora, min_df=2)\n",
    "vocab = vectorizer.fit_transform(corpora)\n",
    "tokens = vectorizer.get_feature_names()\n",
    "#print(vocab.toarray())\n",
    "#print(vocab[0])\n",
    "#print(tokens[2389])\n",
    "#print(corpora[0])\n",
    "\n",
    "#initialize some values\n",
    "vocabA = vocab.toarray()\n",
    "\n",
    "#randomly initialize weights to start off with \n",
    "weights = []\n",
    "for i in range(len(vectorizer.get_feature_names())):\n",
    "    weights.append(np.random.rand())\n",
    "\n",
    "#function to compute dot product\n",
    "def dot(weights, feature):\n",
    "    output = 0\n",
    "    for i in range(len(weights)):\n",
    "        output += weights[i]*feature[i]\n",
    "    return output\n",
    "\n",
    "for i in range(10):\n",
    "    #calculate model guess\n",
    "    output = dot(weights, vocabA[i])\n",
    "    print(vocabA[i])\n",
    "\n",
    "    print(output)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "16dd1f0e6febe29089962fb2487a942d8d2b9927ae6d9b119e77798fd68476cf"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
